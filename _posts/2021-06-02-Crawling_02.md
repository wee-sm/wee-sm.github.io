---
layout: single
title: "#Crawling by Google Search with Selenium"
---

### Request가 너무 막혀서(429) selenium을 활용해 보았다


```python
import pandas as pd
import numpy as np
import re
import time

import requests
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
```

#### 연예인 이름파일 로드


```python
df_comedians = pd.read_excel("./datas/celebrities_names.xlsx", sheet_name=0)
df_singers = pd.read_excel("./datas/celebrities_names.xlsx", sheet_name=1)
df_actors = pd.read_excel("./datas/celebrities_names.xlsx", sheet_name=2)
```

#### selenium option set


```python
# 옵션값 지정
options = webdriver.ChromeOptions()
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")

# options.headless = True
# options.add_argument("window-size=1920x1080")

browser = webdriver.Chrome("./datas/chromedriver.exe", options=options)
# browser.maximize_window()
```


```python
#### seletion function set
```


```python
def addSexHeightbyGoogle(df):
    for index, row in df.iterrows():
        job = row[0]
        name = row[1]
        if (pd.isna(row[2]) | pd.isna(row[3])):
            print(index, name, end="")
        
        # sex
        if pd.isna(row[2]):
            request_url = "https://www.google.com/search?q=" + job + "+" + name + "+성별"
            browser.get(request_url)
            time.sleep(1) # add sleep to avoid 429
            
            soup = BeautifulSoup(browser.page_source)
            male_count = len([m.start() for m in re.finditer('남성', soup.get_text())])
            female_count = len([m.start() for m in re.finditer('여성', soup.get_text())])
            if male_count > female_count: sex = "m"
            elif male_count < female_count: sex = "w"
            else: sex = np.nan
            
            df.iloc[index, 2] = sex
            print(sex, end="")

        # height
        if pd.isna(row[3]):
            request_url = "https://www.google.com/search?q=" + job + "+" + name + "+키"
            browser.get(request_url)
            time.sleep(1) # add sleep to avoid 429
            
            soup = BeautifulSoup(browser.page_source)
            try:
                h = soup.select('div.Z0LcW.XcVN5d')[0].get_text().replace(" ", "").replace("″", "")
                height = round((int(h.partition("′")[0]) * 12 + int(h.partition("′")[-1])) * 2.54)
            except: 
                try:
                    height = int(soup.get_text().split("cm")[0][-3:])
                except:
                    height = np.nan
                
            df.iloc[index, 3] = height
            print(height, end="")
            
        ##################### CAPTCHA ####################
        if soup.select('#captcha-form'):
            return print("CAPTCHA!!!")
        
        print(" | ", end="")
```

#### funtion 실행


```python
addSexHeightbyGoogle(df_comedians)
```

    0 강석nan165 | 1 강성범m170 | 2 강일구m173 | 3 강유미w165 ...

```python
addSexHeightbyGoogle(df_singers)
```

    0 강산에175 | 1 강성훈175 | 2 강승윤180 | 3 강인봉nan ... 


```python
addSexHeightbyGoogle(df_actors)
```

    0 감우성175 | 1 강경준183 | 2 강기영178 | 3 강남길nan ...


```python
with pd.ExcelWriter('./datas/celebrities_added.xlsx') as writer:
    df_comedians.to_excel(writer, sheet_name='comedians')
    df_singers.to_excel(writer, sheet_name='singers')
    df_actors.to_excel(writer, sheet_name='actors')
```
